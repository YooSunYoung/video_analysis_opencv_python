{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import git\n",
    "repo = git.Repo('.', search_parent_directories=True)\n",
    "sys.path.append(repo.working_tree_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "from blink_detection import simple_model\n",
    "from video_processing_utilities.image_utils import adjust_image_size\n",
    "from video_processing_utilities.image_utils import adjust_image_brightness\n",
    "from video_processing_utilities.image_utils import find_eyes_from_image\n",
    "from video_processing_utilities.image_utils import closed_or_open\n",
    "from video_processing_utilities.image_utils import find_pupils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# load a video and parameters where we already tuned\n",
    "data_root_dir = repo.working_tree_dir+\"/data/\"\n",
    "#metadata_path = os.path.join(data_root_dir, \"data/videos/sample_video.json\")\n",
    "metadata_path = os.path.join(data_root_dir, \"epilepsy/disk-2/2020-06-30_08-17-33.488151/camera/output.json\")\n",
    "with open(metadata_path) as f:\n",
    "    metadata = json.load(f)\n",
    "#video_path = os.path.join(data_root_dir, metadata['video_path'])\n",
    "video_path = os.path.join('/work/data/', metadata['video_path'])\n",
    "brightness = metadata.get('brightness', 2)\n",
    "contour_threshold = metadata.get('contour_threshold', 20)\n",
    "scale_factor = metadata.get('size_scale_factor', 0.5)\n",
    "minimum_pupil_radius = metadata.get('pupil_minimum_radius', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# load video as cv2 VideoCapture\n",
    "capture = cv2.VideoCapture(video_path)\n",
    "# size of the video\n",
    "video_width = int(capture.get(3) * scale_factor)\n",
    "video_height = int(capture.get(4) * scale_factor)\n",
    "# we will update this when we can find eyes and use it for the next frame where we can't find any eyes\n",
    "tmp_eye_zones = [[0, 0, video_width, video_height], [0, 0, video_width, video_height]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# cascade classifier to find where eyes are in each frame\n",
    "haarcasecade_dir = os.path.dirname(cv2.__file__)\n",
    "eye_cascade_path = os.path.join(haarcasecade_dir, \"data\", \"haarcascade_righteye_2splits.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n",
    "if eye_cascade.empty():\n",
    "    print(\"Can't load eyes cascade\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 22, 22, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 9, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 613,889\n",
      "Trainable params: 613,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# blob detector to find pupil in the threshold image of eyes\n",
    "param = cv2.SimpleBlobDetector_Params()\n",
    "param.blobColor = 255\n",
    "param.minArea = 40\n",
    "param.minCircularity = 0.01\n",
    "param.minConvexity = 0.4\n",
    "blob_detector = cv2.SimpleBlobDetector_create(param)\n",
    "# binary classification model to determine if an eye is open or closed\n",
    "model = simple_model()\n",
    "checkpoint_path = '../../data/weight_files/model'\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../result/epilepsy/disk-2/2020-07-02_08-22-08.781451/camera/\n"
     ]
    }
   ],
   "source": [
    "# save output as a csv file\n",
    "output_directory = '../../result/'+metadata['video_path'].replace('output.h264', '')\n",
    "print(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "f = open(os.path.join(output_directory, 'result.csv'), 'w')\n",
    "result_csv = csv.writer(f)\n",
    "result_csv.writerow(['frame_num',\n",
    "                     'left_eye_x', 'left_eye_y', 'left_eye_r',\n",
    "                     'right_eye_x', 'right_eye_y', 'right_eye_r'])\n",
    "# save the result as a video (if needed)\n",
    "visualize_result = True\n",
    "visualize_result_realtime = False\n",
    "if visualize_result:\n",
    "    video_writer = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    video_output = cv2.VideoWriter(os.path.join(output_directory, 'output.avi'),\n",
    "                                   video_writer, 5,\n",
    "                                   (2200, 1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# close or release all resources\n",
    "def terminate():\n",
    "    f.close()\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    if visualize_result:\n",
    "        video_output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# if you want to use only a small part of the video\n",
    "frame_ranges = [range(0, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# for the full video\n",
    "frame_ranges = [range(0, int(capture.get(cv2.CAP_PROP_FRAME_COUNT)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for frame_range in frame_ranges:\n",
    "    capture.set(1, frame_range[0])\n",
    "    for frame_number in frame_range:\n",
    "        ret, frame = capture.read()\n",
    "        if ret is False:\n",
    "            print(\"Failed to open the video\")\n",
    "            terminate()\n",
    "            exit(FileNotFoundError)\n",
    "        # Video Size Adjustment\n",
    "        frame = adjust_image_size(frame, scale_factor)\n",
    "        # Video Brightness Adjustment\n",
    "        frame = adjust_image_brightness(frame, brightness)\n",
    "        # Video Contrast Adjustment should be followed\n",
    "\n",
    "        # find eyes\n",
    "        eye_zones = find_eyes_from_image(frame, eye_cascade)\n",
    "        # if you could find two eyes\n",
    "        if eye_zones is not None and len(eye_zones) > 1:\n",
    "            tmp_eye_zones = eye_zones  # if eyes were not found, assume eyes are still at the same place.\n",
    "        # eyes_closed = closed_or_open(tmp_eye_zones, frame, model)\n",
    "        eyes_closed = [0, 0]\n",
    "        # if 0 in eyes_closed or len(eye_zones) < 2:\n",
    "        for ir, result in enumerate(eyes_closed):\n",
    "            cv2.putText(frame, str(result), (50 * ir, 200), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n",
    "        result_row = [frame_number]\n",
    "        if (eye_zones is None or len(eye_zones) < 2) and 0 in eyes_closed:\n",
    "            cv2.putText(frame, \"Eyes Closed\", (50, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n",
    "        else:\n",
    "            # find pupils\n",
    "            pupils_eyes = find_pupils(eye_zones, frame, contour_threshold,\n",
    "                                      blob_detector, minimum_area=100, visualize=visualize_result,\n",
    "                                      minimum_radius=minimum_pupil_radius)\n",
    "            if visualize_result:\n",
    "                pupils, eyes = pupils_eyes\n",
    "            else: pupils = pupils_eyes\n",
    "            # draw eyes and pupils\n",
    "            tmp = []\n",
    "            for (x1, y1, x2, y2), (img, x, y, r) in zip(eye_zones[:2], pupils[:2]):\n",
    "                if r < minimum_pupil_radius:\n",
    "                    cv2.putText(frame, \"Can't find pupil\", (150, 150), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n",
    "                    break\n",
    "                tmp.append(x)\n",
    "                tmp.append(y)\n",
    "                tmp.append(r)\n",
    "                frame = cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                frame = cv2.circle(frame, (x, y), 0, (0, 0, 255), thickness=5)\n",
    "            width = max(frame.shape[1], eyes.shape[1])\n",
    "            eyes = cv2.copyMakeBorder(eyes, 0, 0, 0, width - eyes.shape[1], cv2.BORDER_CONSTANT)\n",
    "            frame = cv2.copyMakeBorder(frame, 0, 0, 0, width - frame.shape[1], cv2.BORDER_CONSTANT)\n",
    "            frame = np.concatenate((frame, eyes), axis=0)\n",
    "            for i in tmp:\n",
    "                result_row.append(i)\n",
    "\n",
    "        frame = cv2.copyMakeBorder(frame, 0, 1500 - frame.shape[0],\n",
    "                                   0, 2200 - frame.shape[1], cv2.BORDER_CONSTANT)\n",
    "        if visualize_result:\n",
    "            video_output.write(frame)\n",
    "        if visualize_result_realtime:\n",
    "            cv2.imshow(\"Video Analysis\", frame)\n",
    "        result_csv.writerow(result_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
